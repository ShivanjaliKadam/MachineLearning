{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bLVZ_tg_btFD",
    "outputId": "91e4d5b9-80a3-443c-fa34-fe31fd82dd4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "mUQTePJah5XG"
   },
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping, Callback\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "G7hwwyQJkZWv"
   },
   "outputs": [],
   "source": [
    "audio_dataset_path ='/content/drive/MyDrive/Colab Notebooks/Poultry Vocalization Signal Dataset for Early DiseaseÂ Detection/Chicken_Audio_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "tZ619sbnkj5G"
   },
   "outputs": [],
   "source": [
    "file_paths=[]\n",
    "classes=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "bPsMzIDZknDs"
   },
   "outputs": [],
   "source": [
    "for folder_name in os.listdir(audio_dataset_path):\n",
    "    folder_path = os.path.join(audio_dataset_path, folder_name)\n",
    "\n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Iterate through each file in the folder\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith('.wav'):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                file_paths.append(file_path)\n",
    "                classes.append(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gQjmuDtzkoyq",
    "outputId": "ddad809a-4443-4ba6-8e3d-b46829f6fc9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           file_path  class\n",
      "0  /content/drive/MyDrive/Colab Notebooks/Poultry...  Noise\n",
      "1  /content/drive/MyDrive/Colab Notebooks/Poultry...  Noise\n",
      "2  /content/drive/MyDrive/Colab Notebooks/Poultry...  Noise\n",
      "3  /content/drive/MyDrive/Colab Notebooks/Poultry...  Noise\n",
      "4  /content/drive/MyDrive/Colab Notebooks/Poultry...  Noise\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame from the collected file paths and classes\n",
    "metadata = pd.DataFrame({'file_path': file_paths, 'class': classes})\n",
    "print(metadata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "jANLA9gMkt2h"
   },
   "outputs": [],
   "source": [
    "# Function to extract MFCC features\n",
    "def features_extractor(file):\n",
    "    audio, sample_rate = librosa.load(file, res_type='kaiser_fast')\n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T, axis=0)\n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rkRJcJuQYfdX",
    "outputId": "d40987d2-1096-463c-91df-ab4af82aec40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: resampy in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from resampy) (1.25.2)\n",
      "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.10/dist-packages (from resampy) (0.58.1)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.53->resampy) (0.41.1)\n"
     ]
    }
   ],
   "source": [
    "%pip install resampy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MBizubpcYTIO",
    "outputId": "63f84a01-f36c-47bc-8490-e79aa6641b38"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "346it [02:01,  2.84it/s]\n"
     ]
    }
   ],
   "source": [
    "extracted_features = []\n",
    "for _, row in tqdm(metadata.iterrows()):\n",
    "    file_name = row['file_path']\n",
    "    final_class_labels = row['class']\n",
    "    data = features_extractor(file_name)\n",
    "    extracted_features.append([data, final_class_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "FeSx6PAfag8V",
    "outputId": "cef143f4-f7d2-42dd-ae27-06328797becb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"extracted_features_df\",\n  \"rows\": 346,\n  \"fields\": [\n    {\n      \"column\": \"feature\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Noise\",\n          \"Unhealthy\",\n          \"Healthy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "extracted_features_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-e01e6941-8c52-4bdb-8a78-fe4ec54c2e5a\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-205.92746, 134.27495, -38.85105, 32.43706, 4...</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-196.6323, 126.03945, -37.07014, 25.206053, 4...</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-160.9021, 126.01377, -54.62678, 15.125531, 3...</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-185.45374, 122.36359, -53.871494, 21.235067,...</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-252.11371, 123.52367, 1.0157044, 15.540068, ...</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e01e6941-8c52-4bdb-8a78-fe4ec54c2e5a')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-e01e6941-8c52-4bdb-8a78-fe4ec54c2e5a button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-e01e6941-8c52-4bdb-8a78-fe4ec54c2e5a');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-969ada4e-daa2-4f89-b289-8137d8013015\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-969ada4e-daa2-4f89-b289-8137d8013015')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-969ada4e-daa2-4f89-b289-8137d8013015 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                             feature  class\n",
       "0  [-205.92746, 134.27495, -38.85105, 32.43706, 4...  Noise\n",
       "1  [-196.6323, 126.03945, -37.07014, 25.206053, 4...  Noise\n",
       "2  [-160.9021, 126.01377, -54.62678, 15.125531, 3...  Noise\n",
       "3  [-185.45374, 122.36359, -53.871494, 21.235067,...  Noise\n",
       "4  [-252.11371, 123.52367, 1.0157044, 15.540068, ...  Noise"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df = pd.DataFrame(extracted_features, columns=['feature', 'class'])\n",
    "extracted_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qw14Fny2bn_L",
    "outputId": "5e9cb49b-f91c-4bbd-deb9-202e17eb6bb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix:\n",
      "          0         1         2         3         4         5         6   \\\n",
      "0   1.000000 -0.084022 -0.472368  0.082619 -0.016616 -0.193276 -0.109448   \n",
      "1  -0.084022  1.000000 -0.392929 -0.692003  0.442662  0.315838  0.346728   \n",
      "2  -0.472368 -0.392929  1.000000  0.198509 -0.404642  0.126406  0.126119   \n",
      "3   0.082619 -0.692003  0.198509  1.000000 -0.267005 -0.288090 -0.356705   \n",
      "4  -0.016616  0.442662 -0.404642 -0.267005  1.000000 -0.210011  0.114038   \n",
      "5  -0.193276  0.315838  0.126406 -0.288090 -0.210011  1.000000  0.324009   \n",
      "6  -0.109448  0.346728  0.126119 -0.356705  0.114038  0.324009  1.000000   \n",
      "7   0.228053 -0.755363  0.315047  0.688059 -0.288505 -0.215461 -0.382201   \n",
      "8   0.204014  0.133652 -0.370279  0.018329  0.381572 -0.325044  0.146928   \n",
      "9  -0.058614 -0.319336  0.594330  0.167913 -0.596767  0.445688  0.120702   \n",
      "10  0.161213  0.224384 -0.162254 -0.257884  0.326724 -0.088769  0.434915   \n",
      "11  0.120999 -0.570800  0.265931  0.560949 -0.550182  0.042563 -0.170941   \n",
      "12  0.131606  0.055439 -0.019067 -0.064091  0.470025 -0.329701  0.222346   \n",
      "13  0.089743 -0.374271  0.410951  0.082105 -0.464547  0.324917  0.168508   \n",
      "14 -0.114418  0.300156 -0.036419 -0.125264  0.410057 -0.154240  0.467945   \n",
      "15  0.226238 -0.456301 -0.118716  0.414483 -0.308537 -0.053780 -0.423160   \n",
      "16  0.216749 -0.101098  0.275405 -0.097694 -0.016601 -0.066572  0.593418   \n",
      "17  0.133751 -0.270719  0.306629  0.108073 -0.532449  0.296438  0.150405   \n",
      "18  0.158984 -0.210381 -0.270517  0.389672  0.102186 -0.346153 -0.216336   \n",
      "19  0.073466  0.281076  0.044472 -0.516183  0.112650  0.227291  0.322847   \n",
      "20  0.130452 -0.523295  0.338100  0.451184 -0.291096  0.007917  0.195634   \n",
      "21  0.200870  0.037434  0.164508 -0.278629 -0.114127  0.140190  0.288874   \n",
      "22  0.200986 -0.082829 -0.413288  0.314500  0.038696 -0.219028 -0.061060   \n",
      "23 -0.003569 -0.153448  0.487203 -0.234337 -0.288107  0.331680  0.224524   \n",
      "24  0.153530  0.323496 -0.387478 -0.130492  0.220201 -0.016127  0.525582   \n",
      "25  0.217431 -0.287867 -0.054481  0.199505  0.012214 -0.034116 -0.316005   \n",
      "26 -0.038332  0.039598  0.319858 -0.164992 -0.027265 -0.061132  0.122414   \n",
      "27  0.119912  0.064965 -0.323348  0.068763 -0.000376  0.105958  0.323932   \n",
      "28  0.130972  0.029501  0.325855 -0.278989 -0.003426  0.171256  0.402429   \n",
      "29  0.348634 -0.100994  0.037327 -0.079969 -0.117336  0.040065  0.266950   \n",
      "30 -0.169627  0.234798 -0.260995 -0.011809  0.113587  0.072668  0.013103   \n",
      "31  0.304657  0.100498 -0.093962 -0.297893  0.107154  0.110267  0.280199   \n",
      "32  0.143943 -0.024018  0.228379 -0.130140  0.027381  0.125725  0.412145   \n",
      "33 -0.044053 -0.167924  0.022459  0.209933 -0.146959  0.182438 -0.212640   \n",
      "34  0.246706  0.201048 -0.009281 -0.316136  0.245516 -0.160753  0.414609   \n",
      "35 -0.077827  0.030680 -0.111645  0.156336 -0.074879  0.113378 -0.109008   \n",
      "36  0.154985 -0.216149  0.450548 -0.121339 -0.286376  0.135832  0.181182   \n",
      "37  0.200354  0.106397 -0.337644 -0.082643  0.279326 -0.342185 -0.035876   \n",
      "38 -0.230422 -0.025398  0.074991  0.094204 -0.192856  0.143848 -0.217198   \n",
      "39  0.091277 -0.145320  0.157973 -0.021585  0.002470 -0.196620  0.006820   \n",
      "\n",
      "          7         8         9   ...        30        31        32        33  \\\n",
      "0   0.228053  0.204014 -0.058614  ... -0.169627  0.304657  0.143943 -0.044053   \n",
      "1  -0.755363  0.133652 -0.319336  ...  0.234798  0.100498 -0.024018 -0.167924   \n",
      "2   0.315047 -0.370279  0.594330  ... -0.260995 -0.093962  0.228379  0.022459   \n",
      "3   0.688059  0.018329  0.167913  ... -0.011809 -0.297893 -0.130140  0.209933   \n",
      "4  -0.288505  0.381572 -0.596767  ...  0.113587  0.107154  0.027381 -0.146959   \n",
      "5  -0.215461 -0.325044  0.445688  ...  0.072668  0.110267  0.125725  0.182438   \n",
      "6  -0.382201  0.146928  0.120702  ...  0.013103  0.280199  0.412145 -0.212640   \n",
      "7   1.000000 -0.221313  0.326469  ... -0.375942  0.074357  0.127978  0.080661   \n",
      "8  -0.221313  1.000000 -0.405496  ...  0.265823 -0.088991  0.008150 -0.080392   \n",
      "9   0.326469 -0.405496  1.000000  ... -0.166986  0.038562  0.235105  0.119265   \n",
      "10 -0.227192  0.452550 -0.388280  ...  0.086511  0.355194  0.074986 -0.016528   \n",
      "11  0.497170 -0.155843  0.622638  ...  0.093309 -0.244666  0.007602  0.209464   \n",
      "12 -0.040491  0.470170 -0.324688  ... -0.101253  0.200042  0.238804 -0.037628   \n",
      "13  0.319568 -0.236310  0.616236  ... -0.446681  0.251354  0.511617 -0.178322   \n",
      "14 -0.297541  0.299593 -0.156564  ...  0.314313 -0.034441  0.000038  0.041119   \n",
      "15  0.450415  0.067893  0.063174  ...  0.066716 -0.169074 -0.062187  0.161750   \n",
      "16  0.075389  0.142807  0.269139  ... -0.302216  0.437693  0.484921 -0.188034   \n",
      "17  0.264273 -0.172124  0.561776  ... -0.002377  0.138389  0.192279  0.171284   \n",
      "18  0.078727  0.392214 -0.240639  ...  0.543182 -0.290613 -0.472120  0.361714   \n",
      "19 -0.090461 -0.161578  0.158569  ... -0.451165  0.510127  0.552470 -0.347756   \n",
      "20  0.432252  0.087746  0.344950  ... -0.357494  0.149882  0.380658 -0.056613   \n",
      "21  0.013005 -0.130760  0.366628  ...  0.039290  0.326614  0.229083  0.170961   \n",
      "22 -0.010172  0.442893 -0.323626  ...  0.282782 -0.137688 -0.232411  0.106113   \n",
      "23  0.191991 -0.388743  0.559033  ... -0.326803  0.276776  0.465702 -0.074921   \n",
      "24 -0.342330  0.376790 -0.239814  ...  0.341970  0.223793 -0.068749  0.108309   \n",
      "25  0.265739  0.038902  0.103438  ...  0.098813 -0.068248 -0.009965  0.176204   \n",
      "26  0.127687 -0.080008  0.169289  ... -0.636514  0.400667  0.434001 -0.374024   \n",
      "27 -0.255529  0.198765  0.008783  ...  0.620385 -0.127515 -0.218196  0.317110   \n",
      "28  0.123149 -0.102393  0.238167  ... -0.390410  0.498880  0.530641 -0.086144   \n",
      "29  0.173432  0.011600  0.250872  ... -0.651068  0.488506  0.689407 -0.385229   \n",
      "30 -0.375942  0.265823 -0.166986  ...  1.000000 -0.420787 -0.581879  0.529975   \n",
      "31  0.074357 -0.088991  0.038562  ... -0.420787  1.000000  0.293454 -0.098358   \n",
      "32  0.127978  0.008150  0.235105  ... -0.581879  0.293454  1.000000 -0.494362   \n",
      "33  0.080661 -0.080392  0.119265  ...  0.529975 -0.098358 -0.494362  1.000000   \n",
      "34 -0.056234  0.120732 -0.001543  ... -0.465058  0.420022  0.651272 -0.579985   \n",
      "35 -0.080934 -0.032230 -0.165542  ...  0.428135 -0.150867 -0.494098  0.510473   \n",
      "36  0.317049 -0.234130  0.506614  ... -0.580948  0.366590  0.638115 -0.313707   \n",
      "37 -0.178440  0.338188 -0.477974  ...  0.181792  0.105690 -0.177317  0.086096   \n",
      "38 -0.094601 -0.047783  0.175795  ...  0.745304 -0.446444 -0.569069  0.559112   \n",
      "39  0.210937 -0.054820 -0.047131  ... -0.861702  0.334238  0.550991 -0.606917   \n",
      "\n",
      "          34        35        36        37        38        39  \n",
      "0   0.246706 -0.077827  0.154985  0.200354 -0.230422  0.091277  \n",
      "1   0.201048  0.030680 -0.216149  0.106397 -0.025398 -0.145320  \n",
      "2  -0.009281 -0.111645  0.450548 -0.337644  0.074991  0.157973  \n",
      "3  -0.316136  0.156336 -0.121339 -0.082643  0.094204 -0.021585  \n",
      "4   0.245516 -0.074879 -0.286376  0.279326 -0.192856  0.002470  \n",
      "5  -0.160753  0.113378  0.135832 -0.342185  0.143848 -0.196620  \n",
      "6   0.414609 -0.109008  0.181182 -0.035876 -0.217198  0.006820  \n",
      "7  -0.056234 -0.080934  0.317049 -0.178440 -0.094601  0.210937  \n",
      "8   0.120732 -0.032230 -0.234130  0.338188 -0.047783 -0.054820  \n",
      "9  -0.001543 -0.165542  0.506614 -0.477974  0.175795 -0.047131  \n",
      "10  0.312646 -0.079594 -0.058028  0.505950 -0.250627 -0.032807  \n",
      "11 -0.153589 -0.032981  0.223846 -0.289601  0.366442 -0.216956  \n",
      "12  0.303700 -0.162502 -0.001642  0.319067 -0.327932  0.186732  \n",
      "13  0.281003 -0.368704  0.580169 -0.208582 -0.267902  0.261276  \n",
      "14  0.122572  0.029244 -0.282764  0.143665 -0.012675 -0.221615  \n",
      "15 -0.240739  0.108629  0.059796 -0.113384  0.246781 -0.113552  \n",
      "16  0.564655 -0.373048  0.402875  0.180632 -0.419157  0.254264  \n",
      "17  0.077536 -0.019030  0.474194 -0.262357  0.243328 -0.193288  \n",
      "18 -0.353937  0.152864 -0.516727  0.412151  0.268672 -0.428083  \n",
      "19  0.578247 -0.312563  0.554425 -0.156096 -0.353363  0.340732  \n",
      "20  0.065548 -0.186279  0.231698 -0.109355 -0.355726  0.329127  \n",
      "21  0.351486 -0.213367  0.463527  0.065964  0.101187 -0.232854  \n",
      "22 -0.161157  0.120506 -0.477501  0.330540 -0.007384 -0.105968  \n",
      "23  0.303440 -0.235130  0.731672 -0.418944 -0.002575  0.132570  \n",
      "24  0.160743  0.101800 -0.335009  0.410333 -0.084945 -0.259806  \n",
      "25 -0.173115 -0.086448  0.071387  0.039102  0.107654 -0.211798  \n",
      "26  0.502904 -0.349277  0.511816 -0.198434 -0.478175  0.645744  \n",
      "27 -0.189705  0.276574 -0.394260  0.196146  0.321063 -0.602813  \n",
      "28  0.494986 -0.238076  0.661487 -0.148671 -0.257698  0.258568  \n",
      "29  0.584906 -0.461270  0.537900  0.047685 -0.632357  0.599396  \n",
      "30 -0.465058  0.428135 -0.580948  0.181792  0.745304 -0.861702  \n",
      "31  0.420022 -0.150867  0.366590  0.105690 -0.446444  0.334238  \n",
      "32  0.651272 -0.494098  0.638115 -0.177317 -0.569069  0.550991  \n",
      "33 -0.579985  0.510473 -0.313707  0.086096  0.559112 -0.606917  \n",
      "34  1.000000 -0.557138  0.496988  0.098831 -0.539807  0.506622  \n",
      "35 -0.557138  1.000000 -0.413695 -0.037503  0.446684 -0.358964  \n",
      "36  0.496988 -0.413695  1.000000 -0.366270 -0.198892  0.427650  \n",
      "37  0.098831 -0.037503 -0.366270  1.000000 -0.224286 -0.034272  \n",
      "38 -0.539807  0.446684 -0.198892 -0.224286  1.000000 -0.767002  \n",
      "39  0.506622 -0.358964  0.427650 -0.034272 -0.767002  1.000000  \n",
      "\n",
      "[40 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate Correlation Matrix\n",
    "correlation_matrix = extracted_features_df['feature'].apply(pd.Series).corr()\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "UOpP2GXIbtaL"
   },
   "outputs": [],
   "source": [
    "# Binning (Equal Width Bins)\n",
    "num_bins = 10  # Number of bins\n",
    "bin_labels = range(num_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kQz7cywUgyZr",
    "outputId": "a0b5bc61-6c51-4a62-ab12-52834cf5773b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binned Features:\n",
      "                                             feature  \\\n",
      "0  [-205.92746, 134.27495, -38.85105, 32.43706, 4...   \n",
      "1  [-196.6323, 126.03945, -37.07014, 25.206053, 4...   \n",
      "2  [-160.9021, 126.01377, -54.62678, 15.125531, 3...   \n",
      "3  [-185.45374, 122.36359, -53.871494, 21.235067,...   \n",
      "4  [-252.11371, 123.52367, 1.0157044, 15.540068, ...   \n",
      "\n",
      "                                      binned_feature  \n",
      "0  [0, 9, 4, 7, 7, ..., 6, 6, 6, 6, 6]\n",
      "Length: 40...  \n",
      "1  [0, 9, 4, 6, 7, ..., 6, 6, 6, 6, 6]\n",
      "Length: 40...  \n",
      "2  [0, 9, 3, 6, 6, ..., 5, 5, 5, 5, 5]\n",
      "Length: 40...  \n",
      "3  [0, 9, 4, 6, 7, ..., 6, 6, 5, 6, 6]\n",
      "Length: 40...  \n",
      "4  [0, 9, 6, 7, 7, ..., 6, 6, 6, 6, 6]\n",
      "Length: 40...  \n"
     ]
    }
   ],
   "source": [
    "# Apply binning to each feature separately\n",
    "binned_features = []\n",
    "for feature in extracted_features_df['feature']:\n",
    "    binned_feature = pd.cut(feature, bins=num_bins, labels=bin_labels)\n",
    "    binned_features.append(binned_feature)\n",
    "\n",
    "extracted_features_df['binned_feature'] = binned_features\n",
    "print(\"Binned Features:\")\n",
    "print(extracted_features_df[['feature', 'binned_feature']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LoNIf5Hfkxlc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "0ZM-iQ49bz7S"
   },
   "outputs": [],
   "source": [
    "# Normalization\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(np.vstack(extracted_features_df['feature']))\n",
    "for i in range(scaled_features.shape[1]):\n",
    "    extracted_features_df[f'scaled_feature_{i}'] = scaled_features[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "i2XA5iQhh3-i"
   },
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "X = np.array(extracted_features_df[[f'scaled_feature_{i}' for i in range(scaled_features.shape[1])]])\n",
    "y = np.array(extracted_features_df['class'].tolist())\n",
    "label_encoder = LabelEncoder()\n",
    "y = to_categorical(label_encoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "39OcUcHxajkG"
   },
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NssdWMPranSo",
    "outputId": "cdf0f948-637d-4fc3-b7a6-1faed1f3d570"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 40)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               10496     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11267 (44.01 KB)\n",
      "Trainable params: 11267 (44.01 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model Definition\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "CdrSYnu-aqGM"
   },
   "outputs": [],
   "source": [
    "# Custom Callback for Metrics Tracking\n",
    "class MetricsCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        y_pred_binary = np.argmax(y_pred, axis=1)\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(np.argmax(y_test, axis=1), y_pred_binary, target_names=label_encoder.classes_))\n",
    "        accuracy = accuracy_score(np.argmax(y_test, axis=1), y_pred_binary)\n",
    "        print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "metrics_callback = MetricsCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0BNJrBqOcWkx",
    "outputId": "6935bb00-7879-466d-ed19-6608f69459d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.88      0.67      0.76        21\n",
      "       Noise       0.70      0.70      0.70        10\n",
      "   Unhealthy       0.81      1.00      0.89        21\n",
      "\n",
      "    accuracy                           0.81        52\n",
      "   macro avg       0.79      0.79      0.78        52\n",
      "weighted avg       0.81      0.81      0.80        52\n",
      "\n",
      "Test Accuracy: 0.8076923076923077\n",
      "8/8 [==============================] - 1s 54ms/step - loss: 1.1269 - accuracy: 0.3843 - val_loss: 0.7209 - val_accuracy: 0.8269\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.86      0.90      0.88        21\n",
      "       Noise       0.75      0.60      0.67        10\n",
      "   Unhealthy       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.88        52\n",
      "   macro avg       0.86      0.83      0.84        52\n",
      "weighted avg       0.88      0.88      0.88        52\n",
      "\n",
      "Test Accuracy: 0.8846153846153846\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6922 - accuracy: 0.7314 - val_loss: 0.5351 - val_accuracy: 0.8462\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.90      0.90      0.90        21\n",
      "       Noise       0.78      0.70      0.74        10\n",
      "   Unhealthy       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.90        52\n",
      "   macro avg       0.88      0.87      0.87        52\n",
      "weighted avg       0.90      0.90      0.90        52\n",
      "\n",
      "Test Accuracy: 0.9038461538461539\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5419 - accuracy: 0.8306 - val_loss: 0.4446 - val_accuracy: 0.8462\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.90      0.90      0.90        21\n",
      "       Noise       0.78      0.70      0.74        10\n",
      "   Unhealthy       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.90        52\n",
      "   macro avg       0.88      0.87      0.87        52\n",
      "weighted avg       0.90      0.90      0.90        52\n",
      "\n",
      "Test Accuracy: 0.9038461538461539\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.4040 - accuracy: 0.8884 - val_loss: 0.3907 - val_accuracy: 0.8654\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.90      0.90      0.90        21\n",
      "       Noise       0.78      0.70      0.74        10\n",
      "   Unhealthy       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.90        52\n",
      "   macro avg       0.88      0.87      0.87        52\n",
      "weighted avg       0.90      0.90      0.90        52\n",
      "\n",
      "Test Accuracy: 0.9038461538461539\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.3406 - accuracy: 0.9008 - val_loss: 0.3565 - val_accuracy: 0.9038\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.95      0.90      0.93        21\n",
      "       Noise       0.80      0.80      0.80        10\n",
      "   Unhealthy       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.92        52\n",
      "   macro avg       0.90      0.90      0.90        52\n",
      "weighted avg       0.92      0.92      0.92        52\n",
      "\n",
      "Test Accuracy: 0.9230769230769231\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3046 - accuracy: 0.9298 - val_loss: 0.3434 - val_accuracy: 0.9038\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.95      0.90      0.93        21\n",
      "       Noise       0.80      0.80      0.80        10\n",
      "   Unhealthy       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.92        52\n",
      "   macro avg       0.90      0.90      0.90        52\n",
      "weighted avg       0.92      0.92      0.92        52\n",
      "\n",
      "Test Accuracy: 0.9230769230769231\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3089 - accuracy: 0.9215 - val_loss: 0.3355 - val_accuracy: 0.9038\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.95      0.90      0.93        21\n",
      "       Noise       0.80      0.80      0.80        10\n",
      "   Unhealthy       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.92        52\n",
      "   macro avg       0.90      0.90      0.90        52\n",
      "weighted avg       0.92      0.92      0.92        52\n",
      "\n",
      "Test Accuracy: 0.9230769230769231\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.2865 - accuracy: 0.9256 - val_loss: 0.3271 - val_accuracy: 0.9231\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.95      0.90      0.93        21\n",
      "       Noise       0.80      0.80      0.80        10\n",
      "   Unhealthy       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.92        52\n",
      "   macro avg       0.90      0.90      0.90        52\n",
      "weighted avg       0.92      0.92      0.92        52\n",
      "\n",
      "Test Accuracy: 0.9230769230769231\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2539 - accuracy: 0.9339 - val_loss: 0.3215 - val_accuracy: 0.9231\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.95      0.90      0.93        21\n",
      "       Noise       0.80      0.80      0.80        10\n",
      "   Unhealthy       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.92        52\n",
      "   macro avg       0.90      0.90      0.90        52\n",
      "weighted avg       0.92      0.92      0.92        52\n",
      "\n",
      "Test Accuracy: 0.9230769230769231\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.2281 - accuracy: 0.9339 - val_loss: 0.3162 - val_accuracy: 0.9231\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.90      0.90      0.90        21\n",
      "       Noise       0.78      0.70      0.74        10\n",
      "   Unhealthy       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.90        52\n",
      "   macro avg       0.88      0.87      0.87        52\n",
      "weighted avg       0.90      0.90      0.90        52\n",
      "\n",
      "Test Accuracy: 0.9038461538461539\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.2020 - accuracy: 0.9669 - val_loss: 0.3120 - val_accuracy: 0.9423\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.90      0.90      0.90        21\n",
      "       Noise       0.78      0.70      0.74        10\n",
      "   Unhealthy       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.90        52\n",
      "   macro avg       0.88      0.87      0.87        52\n",
      "weighted avg       0.90      0.90      0.90        52\n",
      "\n",
      "Test Accuracy: 0.9038461538461539\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1970 - accuracy: 0.9463 - val_loss: 0.3138 - val_accuracy: 0.9423\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.95      0.90      0.93        21\n",
      "       Noise       0.80      0.80      0.80        10\n",
      "   Unhealthy       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.92        52\n",
      "   macro avg       0.90      0.90      0.90        52\n",
      "weighted avg       0.92      0.92      0.92        52\n",
      "\n",
      "Test Accuracy: 0.9230769230769231\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1632 - accuracy: 0.9504 - val_loss: 0.3140 - val_accuracy: 0.9423\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.95      0.90      0.93        21\n",
      "       Noise       0.80      0.80      0.80        10\n",
      "   Unhealthy       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.92        52\n",
      "   macro avg       0.90      0.90      0.90        52\n",
      "weighted avg       0.92      0.92      0.92        52\n",
      "\n",
      "Test Accuracy: 0.9230769230769231\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1706 - accuracy: 0.9669 - val_loss: 0.3136 - val_accuracy: 0.9423\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.95      0.90      0.93        21\n",
      "       Noise       0.80      0.80      0.80        10\n",
      "   Unhealthy       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.92        52\n",
      "   macro avg       0.90      0.90      0.90        52\n",
      "weighted avg       0.92      0.92      0.92        52\n",
      "\n",
      "Test Accuracy: 0.9230769230769231\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1557 - accuracy: 0.9545 - val_loss: 0.3121 - val_accuracy: 0.9423\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.95      0.90      0.93        21\n",
      "       Noise       0.80      0.80      0.80        10\n",
      "   Unhealthy       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.92        52\n",
      "   macro avg       0.90      0.90      0.90        52\n",
      "weighted avg       0.92      0.92      0.92        52\n",
      "\n",
      "Test Accuracy: 0.9230769230769231\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.1513 - accuracy: 0.9587 - val_loss: 0.3094 - val_accuracy: 0.9423\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.95      0.90      0.93        21\n",
      "       Noise       0.80      0.80      0.80        10\n",
      "   Unhealthy       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.92        52\n",
      "   macro avg       0.90      0.90      0.90        52\n",
      "weighted avg       0.92      0.92      0.92        52\n",
      "\n",
      "Test Accuracy: 0.9230769230769231\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.1395 - accuracy: 0.9669 - val_loss: 0.3075 - val_accuracy: 0.9423\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.95      0.90      0.93        21\n",
      "       Noise       0.80      0.80      0.80        10\n",
      "   Unhealthy       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.92        52\n",
      "   macro avg       0.90      0.90      0.90        52\n",
      "weighted avg       0.92      0.92      0.92        52\n",
      "\n",
      "Test Accuracy: 0.9230769230769231\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1499 - accuracy: 0.9545 - val_loss: 0.3101 - val_accuracy: 0.9423\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.95      0.90      0.93        21\n",
      "       Noise       0.80      0.80      0.80        10\n",
      "   Unhealthy       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.92        52\n",
      "   macro avg       0.90      0.90      0.90        52\n",
      "weighted avg       0.92      0.92      0.92        52\n",
      "\n",
      "Test Accuracy: 0.9230769230769231\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1315 - accuracy: 0.9628 - val_loss: 0.3197 - val_accuracy: 0.9423\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.95      0.90      0.93        21\n",
      "       Noise       0.80      0.80      0.80        10\n",
      "   Unhealthy       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.92        52\n",
      "   macro avg       0.90      0.90      0.90        52\n",
      "weighted avg       0.92      0.92      0.92        52\n",
      "\n",
      "Test Accuracy: 0.9230769230769231\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1321 - accuracy: 0.9752 - val_loss: 0.3261 - val_accuracy: 0.9423\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.95      0.90      0.93        21\n",
      "       Noise       0.80      0.80      0.80        10\n",
      "   Unhealthy       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.92        52\n",
      "   macro avg       0.90      0.90      0.90        52\n",
      "weighted avg       0.92      0.92      0.92        52\n",
      "\n",
      "Test Accuracy: 0.9230769230769231\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1252 - accuracy: 0.9545 - val_loss: 0.3199 - val_accuracy: 0.9423\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.95      0.90      0.93        21\n",
      "       Noise       0.80      0.80      0.80        10\n",
      "   Unhealthy       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.92        52\n",
      "   macro avg       0.90      0.90      0.90        52\n",
      "weighted avg       0.92      0.92      0.92        52\n",
      "\n",
      "Test Accuracy: 0.9230769230769231\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1158 - accuracy: 0.9669 - val_loss: 0.3221 - val_accuracy: 0.9423\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.95      0.90      0.93        21\n",
      "       Noise       0.80      0.80      0.80        10\n",
      "   Unhealthy       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.92        52\n",
      "   macro avg       0.90      0.90      0.90        52\n",
      "weighted avg       0.92      0.92      0.92        52\n",
      "\n",
      "Test Accuracy: 0.9230769230769231\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1053 - accuracy: 0.9711 - val_loss: 0.3274 - val_accuracy: 0.9423\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.95      0.90      0.93        21\n",
      "       Noise       0.80      0.80      0.80        10\n",
      "   Unhealthy       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.92        52\n",
      "   macro avg       0.90      0.90      0.90        52\n",
      "weighted avg       0.92      0.92      0.92        52\n",
      "\n",
      "Test Accuracy: 0.9230769230769231\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1158 - accuracy: 0.9752 - val_loss: 0.3328 - val_accuracy: 0.9423\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.90      0.90      0.90        21\n",
      "       Noise       0.80      0.80      0.80        10\n",
      "   Unhealthy       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           0.92        52\n",
      "   macro avg       0.90      0.90      0.90        52\n",
      "weighted avg       0.92      0.92      0.92        52\n",
      "\n",
      "Test Accuracy: 0.9230769230769231\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0877 - accuracy: 0.9752 - val_loss: 0.3358 - val_accuracy: 0.9423\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.91      0.95      0.93        21\n",
      "       Noise       0.89      0.80      0.84        10\n",
      "   Unhealthy       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           0.94        52\n",
      "   macro avg       0.93      0.92      0.92        52\n",
      "weighted avg       0.94      0.94      0.94        52\n",
      "\n",
      "Test Accuracy: 0.9423076923076923\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1024 - accuracy: 0.9711 - val_loss: 0.3331 - val_accuracy: 0.9423\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.95      0.90      0.93        21\n",
      "       Noise       0.80      0.80      0.80        10\n",
      "   Unhealthy       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.92        52\n",
      "   macro avg       0.90      0.90      0.90        52\n",
      "weighted avg       0.92      0.92      0.92        52\n",
      "\n",
      "Test Accuracy: 0.9230769230769231\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.1041 - accuracy: 0.9669 - val_loss: 0.3331 - val_accuracy: 0.9423\n"
     ]
    }
   ],
   "source": [
    "# Training the Model\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "                    validation_data=(X_val, y_val), callbacks=[early_stopping, metrics_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cV18hWUVcZPC",
    "outputId": "2b271e81-81ec-4e27-c1ca-4027ea39dc45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1978 - accuracy: 0.9231\n",
      "Test Accuracy: 0.9230769276618958\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q5PwpRLIdSKz",
    "outputId": "7581e7f8-1077-48ac-fbec-6adfad85f32a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KDT9srUFp7hO",
    "outputId": "3d88c28a-2b46-44ee-cda3-4c39a9d9d6b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.90      0.90      0.90        21\n",
      "       Noise       0.80      0.80      0.80        10\n",
      "   Unhealthy       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           0.92        52\n",
      "   macro avg       0.90      0.90      0.90        52\n",
      "weighted avg       0.92      0.92      0.92        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(y_pred_binary, axis=1), target_names=label_encoder.classes_))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
